{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-22T15:09:02.708671Z",
     "iopub.status.busy": "2025-12-22T15:09:02.708481Z",
     "iopub.status.idle": "2025-12-22T15:09:14.172125Z",
     "shell.execute_reply": "2025-12-22T15:09:14.171490Z",
     "shell.execute_reply.started": "2025-12-22T15:09:02.708651Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "print(\"Imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T15:09:14.173874Z",
     "iopub.status.busy": "2025-12-22T15:09:14.173508Z",
     "iopub.status.idle": "2025-12-22T15:09:28.292205Z",
     "shell.execute_reply": "2025-12-22T15:09:28.291490Z",
     "shell.execute_reply.started": "2025-12-22T15:09:14.173849Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded.\n"
     ]
    }
   ],
   "source": [
    "# -------- 1. Load data --------\n",
    "df = pd.read_csv(\"/kaggle/input/brad-review-processed/brad_reviews_preprocessed.csv\")  # change name if needed\n",
    "texts = df[\"review_clean\"].astype(str).tolist()\n",
    "print(\"Dataset Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T15:09:28.293451Z",
     "iopub.status.busy": "2025-12-22T15:09:28.293148Z",
     "iopub.status.idle": "2025-12-22T15:09:28.353000Z",
     "shell.execute_reply": "2025-12-22T15:09:28.352286Z",
     "shell.execute_reply.started": "2025-12-22T15:09:28.293425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# -------- 2. Device (GPU) --------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T15:09:28.354207Z",
     "iopub.status.busy": "2025-12-22T15:09:28.353950Z",
     "iopub.status.idle": "2025-12-22T15:09:58.665906Z",
     "shell.execute_reply": "2025-12-22T15:09:58.665273Z",
     "shell.execute_reply.started": "2025-12-22T15:09:28.354184Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbb0398155a43fb90549f66b70344ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/86.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7b46cb578245a19f8492b51b782012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/841 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8487d146684a8093efef7c259f9131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8cf25200eb4d97b626a65fa27dee9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 15:09:35.226546: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766416175.433391      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766416175.493849      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1766416175.944608      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766416175.944642      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766416175.944646      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766416175.944652      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87897798a746460b93d06613fb5f07d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------- 3. Load model & tokenizer --------\n",
    "MODEL_NAME = \"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\"  # 3-class sentiment[web:169]\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T15:09:58.667442Z",
     "iopub.status.busy": "2025-12-22T15:09:58.666850Z",
     "iopub.status.idle": "2025-12-22T15:09:58.673418Z",
     "shell.execute_reply": "2025-12-22T15:09:58.672626Z",
     "shell.execute_reply.started": "2025-12-22T15:09:58.667411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -------- 4. Dataset & DataLoader (with workers) --------\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "def collate_fn(batch_texts):\n",
    "    return tokenizer(\n",
    "        batch_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "dataset = ReviewsDataset(texts)\n",
    "\n",
    "BATCH_SIZE = 128   # try 128, lower to 64 if CUDA OOM\n",
    "NUM_WORKERS = 4    # Kaggle usually handles 2â€“4 workers fine\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T15:09:58.674512Z",
     "iopub.status.busy": "2025-12-22T15:09:58.674311Z",
     "iopub.status.idle": "2025-12-22T15:09:58.690036Z",
     "shell.execute_reply": "2025-12-22T15:09:58.689353Z",
     "shell.execute_reply.started": "2025-12-22T15:09:58.674492Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'positive', 1: 'negative', 2: 'neutral'}\n"
     ]
    }
   ],
   "source": [
    "# -------- 5. Label mapping --------\n",
    "label_map = {\n",
    "    \"negative\": -1,\n",
    "    \"neutral\": 0,\n",
    "    \"positive\": 1,\n",
    "}\n",
    "id2label = model.config.id2label  # e.g. {0: 'negative', 1: 'neutral', 2: 'positive'}[web:169]\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T15:09:58.692316Z",
     "iopub.status.busy": "2025-12-22T15:09:58.692004Z",
     "iopub.status.idle": "2025-12-22T15:09:58.702837Z",
     "shell.execute_reply": "2025-12-22T15:09:58.702085Z",
     "shell.execute_reply.started": "2025-12-22T15:09:58.692293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -------- 6. Inference on GPU --------\n",
    "all_labels = []\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T15:09:58.704176Z",
     "iopub.status.busy": "2025-12-22T15:09:58.703713Z",
     "iopub.status.idle": "2025-12-22T15:09:58.716748Z",
     "shell.execute_reply": "2025-12-22T15:09:58.716099Z",
     "shell.execute_reply.started": "2025-12-22T15:09:58.704152Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.set_grad_enabled(mode=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T15:09:58.717913Z",
     "iopub.status.busy": "2025-12-22T15:09:58.717653Z",
     "iopub.status.idle": "2025-12-22T16:11:53.113043Z",
     "shell.execute_reply": "2025-12-22T16:11:53.111988Z",
     "shell.execute_reply.started": "2025-12-22T15:09:58.717884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ded508cef64440db175566ae8dcfd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3934 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01518300a5e54dcb953d56ce1e814e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in tqdm(loader):\n",
    "    # move batch to GPU\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    outputs = model(**batch)\n",
    "    probs = torch.softmax(outputs.logits, dim=-1)\n",
    "    scores, preds = torch.max(probs, dim=-1)\n",
    "\n",
    "    for p, s in zip(preds.cpu().tolist(), scores.cpu().tolist()):\n",
    "        label_str = id2label[p]\n",
    "        mapped = label_map[label_str]\n",
    "        all_labels.append(mapped)\n",
    "        all_scores.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T16:11:53.115492Z",
     "iopub.status.busy": "2025-12-22T16:11:53.115117Z",
     "iopub.status.idle": "2025-12-22T16:12:09.352018Z",
     "shell.execute_reply": "2025-12-22T16:12:09.351286Z",
     "shell.execute_reply.started": "2025-12-22T16:11:53.115450Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved brad_reviews_with_camel_sentiment_gpu.csv\n"
     ]
    }
   ],
   "source": [
    "# -------- 7. Save results --------\n",
    "df[\"camel_sentiment\"] = all_labels\n",
    "df[\"camel_score\"] = all_scores\n",
    "df.to_csv(\"brad_reviews_with_camel_sentiment_gpu.csv\", index=False)\n",
    "\n",
    "print(\"Saved brad_reviews_with_camel_sentiment_gpu.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9097807,
     "sourceId": 14258006,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
