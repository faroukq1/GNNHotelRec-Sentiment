{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03255c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from pyarabic import araby, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198afa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/row/02_brad_balanced.csv\")\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df = df.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f53d2f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARABIC_RANGE = r\"\\u0600-\\u06FF\"\n",
    "non_arabic_pattern   = re.compile(fr\"[^{ARABIC_RANGE}\\s.!?,؛،؟]+\")\n",
    "elongation_pattern   = re.compile(r\"(.)\\1{2,}\")          # روووعة -> رووعه\n",
    "repeated_punct_pattern = re.compile(r\"([.!?,؛،؟])\\1+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49042a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text: str) -> str:\n",
    "    \"\"\"Remove all emojis from text\"\"\"\n",
    "    return emoji.replace_emoji(text, \"\")\n",
    "\n",
    "\n",
    "def normalize_arabic(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Safely normalize Arabic text:\n",
    "    - remove diacritics (tashkeel)\n",
    "    - remove tatweel\n",
    "    - lightly normalize alif variants\n",
    "    WITHOUT touching ة or hamza positions\n",
    "    (better for Arabic BERT vocabularies).[web:207][web:215]\n",
    "    \"\"\"\n",
    "    # Remove tashkeel (all diacritics)\n",
    "    text = araby.strip_tashkeel(text)\n",
    "    \n",
    "    # Remove tatweel (ـ)\n",
    "    text = araby.strip_tatweel(text)\n",
    "    \n",
    "    # Light alif normalization (keep hamza attached)\n",
    "    text = text.replace(\"إ\", \"ا\").replace(\"أ\", \"ا\").replace(\"آ\", \"ا\").replace(\"ٱ\", \"ا\")\n",
    "    \n",
    "    # IMPORTANT: do NOT change ة -> ه and ى -> ي here\n",
    "    # so words like \"رواية\" و \"عيسى\" تبقى مقروءة جيداً لنماذج BERT[web:154]\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_review(text: str) -> str:\n",
    "    \"\"\"Clean and normalize Arabic review text\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # 1) Remove basic noise: URLs, emails, HTML, digits, mentions, hashtags\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"http[s]?://\\S+|www\\.\\S+\", \" \", text)\n",
    "    text = re.sub(r\"\\S+@\\S+\", \" \", text)\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", \" \", text)\n",
    "    text = re.sub(r\"#[^\\s]+\", \" \", text)\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    \n",
    "    # 2) Remove emojis\n",
    "    text = remove_emojis(text)\n",
    "    \n",
    "    # 3) Arabic normalization + remove tashkeel\n",
    "    text = normalize_arabic(text)\n",
    "    \n",
    "    # 4) Keep only Arabic + basic punctuation\n",
    "    text = non_arabic_pattern.sub(\" \", text)\n",
    "    \n",
    "    # 5) Collapse elongated letters: روووووعة -> رووعة\n",
    "    text = elongation_pattern.sub(r\"\\1\\1\", text)\n",
    "    \n",
    "    # 6) Normalize punctuation and spaces\n",
    "    text = repeated_punct_pattern.sub(r\"\\1\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b1c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- apply + filter --------\n",
    "df[\"review_clean\"] = df[\"review\"].astype(str).apply(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73282302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2499 very short reviews (< 10 chars).\n"
     ]
    }
   ],
   "source": [
    "MIN_CHARS = 10\n",
    "before = len(df)\n",
    "df = df[df[\"review_clean\"].str.len() >= MIN_CHARS].reset_index(drop=True)\n",
    "after = len(df)\n",
    "print(f\"Removed {before - after} very short reviews (< {MIN_CHARS} chars).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eade36f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   review  \\\n",
      "154002  من الكتب الرائده والأولى في مجال العلاقات الإن...   \n",
      "154003  كتاب التاو تي تشينغ _ إنجيل الحكمة التاوية في ...   \n",
      "154004  عجبنى التفاصيل، تفاصيل كتير جدا ودى اكتر حاجة ...   \n",
      "154005  رغم مشاهدة سلسلة الأفلام، إلا أنه للرواية طعم ...   \n",
      "154006                           واقعا كيف كردم از خوندنش   \n",
      "\n",
      "                                             review_clean  \n",
      "154002  من الكتب الرائده والاولى في مجال العلاقات الان...  \n",
      "154003  كتاب التاو تي تشينغ انجيل الحكمة التاوية في ال...  \n",
      "154004  عجبنى التفاصيل، تفاصيل كتير جدا ودى اكتر حاجة ...  \n",
      "154005  رغم مشاهدة سلسلة الافلام، الا انه للرواية طعم ...  \n",
      "154006                           واقعا كيف كردم از خوندنش  \n"
     ]
    }
   ],
   "source": [
    "print(df[[\"review\", \"review_clean\"]].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b848a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: brad_reviews_preprocessed_advanced.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"../../data/processed/02_brad_balanced_processed.csv\", index=False)\n",
    "print(\"Saved: brad_reviews_preprocessed_advanced.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
